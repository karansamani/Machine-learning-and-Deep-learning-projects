{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-Y2-ndn8lpD",
        "outputId": "af6a6a33-ae48-485e-da07-828e69097a86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==1.0.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjrN_CH7uWks",
        "outputId": "251266d5-2f63-432e-9c74-794db778fc1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets==1.0.2 in /usr/local/lib/python3.9/dist-packages (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets==1.0.2) (1.4.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets==1.0.2) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from datasets==1.0.2) (3.10.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets==1.0.2) (2.27.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from datasets==1.0.2) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.9/dist-packages (from datasets==1.0.2) (9.0.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from datasets==1.0.2) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets==1.0.2) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==1.0.2) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==1.0.2) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==1.0.2) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KQI4beK724N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a407c18e-81c8-4a82-e4a0-d225f5faf65b"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ressj5OzXrCc"
      },
      "source": [
        "# if not os.path.exists('/content/drive/MyDrive/BERT-SQuAD'):\n",
        "#   os.mkdir('/content/drive/MyDrive/BERT-SQuAD')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tynjRm_PoeJ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qdgfXtJ-oeMy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hJp-7Oc73vf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c9863c-6e92-4244-d31f-56fa84551ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/1244d044b266a5e4dbd4174d23cb995eead372fbca31a03edc3f8a132787af41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({'train': Dataset(features: {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}, num_rows: 87599), 'validation': Dataset(features: {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}, num_rows: 10570)})\n",
            "\n",
            "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}, 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'id': '5733be284776f41900661182', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'title': 'University_of_Notre_Dame'}\n",
            "\n",
            "Context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "\n",
            "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Download the SQuAD dataset\n",
        "dataset = load_dataset('squad')\n",
        "print(dataset)\n",
        "print()\n",
        "# Print the first example in the training set\n",
        "print(dataset['train'][0])\n",
        "print()\n",
        "# Access the context and question of the first example\n",
        "context = dataset['train'][0]['context']\n",
        "question = dataset['train'][0]['question']\n",
        "\n",
        "# Print the context and question\n",
        "print('Context:', context)\n",
        "print()\n",
        "print('Question:', question)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset['train']\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGudwQ22ps1O",
        "outputId": "4a28f5a2-8b91-4047-e04f-d616a0457ab5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(features: {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}, num_rows: 87599)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrlQcJGjps4T",
        "outputId": "ecbaa89a-7720-48da-ec30-fe2606c3cf6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87599"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V7EBmN9qQ3M",
        "outputId": "87032dc5-a894-450a-8692-0e29ec795b0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}, 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'id': '5733be284776f41900661182', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'title': 'University_of_Notre_Dame'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0]['context'])\n",
        "print(train_data[0]['question'])\n",
        "print(train_data[0]['answers']['text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhbTTRfqqDP8",
        "outputId": "5178b25f-e724-436c-d464-847969282fad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
            "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
            "Saint Bernadette Soubirous\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[99]['context'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRNS09YztIGv",
        "outputId": "60061b1a-d049-4f32-b4bc-0840ecb0a917"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One of the main driving forces in the growth of the University was its football team, the Notre Dame Fighting Irish. Knute Rockne became head coach in 1918. Under Rockne, the Irish would post a record of 105 wins, 12 losses, and five ties. During his 13 years the Irish won three national championships, had five undefeated seasons, won the Rose Bowl in 1925, and produced players such as George Gipp and the \"Four Horsemen\". Knute Rockne has the highest winning percentage (.881) in NCAA Division I/FBS football history. Rockne's offenses employed the Notre Dame Box and his defenses ran a 7‚Äì2‚Äì2 scheme. The last game Rockne coached was on December 14, 1930 when he led a group of Notre Dame all-stars against the New York Giants in New York City.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "context = []\n",
        "question = []\n",
        "answer = []\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "\n",
        "    context.append(train_data[i]['context'])\n",
        "    question.append(train_data[i]['question'])\n",
        "    answer.append(train_data[i]['answers'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUFqekHfp6M9",
        "outputId": "45208f72-7020-4cfc-b282-71ff043a7ea4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.1 s, sys: 216 ms, total: 17.3 s\n",
            "Wall time: 19.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(context))\n",
        "print(len(question))\n",
        "print(len(answer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKxqM6UwqdX-",
        "outputId": "91f74a39-fd7e-40a2-fa54-842b3c878f36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87599\n",
            "87599\n",
            "87599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 4000\n",
        "test_size = 500\n",
        "train_contexts, train_questions, train_answers = context[0:train_size], question[0:train_size], answer[0:train_size]\n",
        "valid_contexts, valid_questions, valid_answers = context[train_size:train_size+test_size], question[train_size:train_size+test_size], answer[train_size:train_size+test_size]"
      ],
      "metadata": {
        "id": "3BgQRc0Qp4rf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_contexts))\n",
        "print(len(train_questions))\n",
        "print(len(train_answers))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nGCigvups7C",
        "outputId": "61314e33-cd8e-43e3-96d0-f434c53ab672"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n",
            "4000\n",
            "4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(valid_contexts))\n",
        "print(len(valid_questions))\n",
        "print(len(valid_answers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jbRW1eQq5sN",
        "outputId": "2f8cfce7-5383-42b0-a11f-a4316fd62d15"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "500\n",
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oER4NnGvFfDG",
        "outputId": "952012a9-3ee6-4a79-beb1-7d79fbf540a6"
      },
      "source": [
        "# print a random question and answer\n",
        "print(f'There are {len(train_questions)} questions')\n",
        "print(train_questions[-1000])\n",
        "print(train_answers[-1000])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4000 questions\n",
            "What place did the game take in Nintendo's Official list of 100 Greatest Nintendo Games of All Time?\n",
            "{'answer_start': [660], 'text': ['16th']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9kiFd7LF6xa"
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "  for answer, context in zip(answers, contexts):\n",
        "    gold_text = answer['text'][0]\n",
        "    start_idx = answer['answer_start'][0] #660\n",
        "    answer['answer_start'] = start_idx\n",
        "    end_idx = start_idx + len(gold_text)\n",
        "    # print(start_idx,gold_text,end_idx)\n",
        "\n",
        "    # sometimes squad answers are off by a character or two so we fix this\n",
        "    if context[start_idx:end_idx] == gold_text:\n",
        "      answer['answer_end'] = end_idx\n",
        "    elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "      answer['answer_start'] = start_idx - 1\n",
        "      answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n",
        "    elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "      answer['answer_start'] = start_idx - 2\n",
        "      answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(valid_answers, valid_contexts)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_answers[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Bs9p2cvFZd",
        "outputId": "75ec635f-ac4a-469f-9592-7fe6f18f3a5e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_start': 727, 'text': ['July 19, 1909'], 'answer_end': 740}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baV-xG3QHGPR",
        "outputId": "983bb236-867e-4eb2-944b-77ff4049511e"
      },
      "source": [
        "# You can see that now we get the answer_end also\n",
        "print(train_questions[-1000])\n",
        "print(train_answers[-1000])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What place did the game take in Nintendo's Official list of 100 Greatest Nintendo Games of All Time?\n",
            "{'answer_start': 660, 'text': ['16th'], 'answer_end': 664}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBLTJaqhHb4J"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True, max_length = 512)\n",
        "valid_encodings = tokenizer(valid_contexts, valid_questions, truncation=True, padding=True, max_length = 512)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy-e5y5sIKCJ",
        "outputId": "8e8e4f05-8ae3-4503-bf8d-f3bb6f2306ab"
      },
      "source": [
        "train_encodings.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK4TXL1CMB0m",
        "outputId": "979dd2bf-c9c3-4426-ee8b-5c1121e4cd69"
      },
      "source": [
        "no_of_encodings = len(train_encodings['input_ids'])\n",
        "print(f'We have {no_of_encodings} context-question pairs')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 4000 context-question pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "D8nEGmjZMIaW",
        "outputId": "70fb4e0e-0915-4454-cafd-381dc90f0722"
      },
      "source": [
        "tokenizer.decode(train_encodings['input_ids'][0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] architecturally, the school has a catholic character. atop the main building\\'s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer ==>Charater starrting and ending points ==> 100,120\n",
        "# Start_Position ==> 25\n",
        "# End_postion ==>  29\n",
        "\n",
        "#  Data we have is==>  answers in character tokens \n",
        "# Question, Context ===>  Answers(words)"
      ],
      "metadata": {
        "id": "ZWf_0vG7Fr00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "encoding has start and end of character indices\n",
        "after the code\n",
        "encoding has start and end of the word indices\n",
        "\n",
        "'''\n",
        "# answer_start ==> 100  character indices\n",
        "#answer_end ==> 120   indices\n",
        "# encodings.char_to_token(i, answers[i]['answer_end'] - 1  ===> fetch the word index"
      ],
      "metadata": {
        "id": "LmTVOQIWIiCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7uXDM0mMfOo"
      },
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "  start_positions = []  # Here, we ar talking word starting position\n",
        "  end_positions = []\n",
        "  for i in range(len(answers)):\n",
        "    start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'])) #9\n",
        "    end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))  #13\n",
        "  # end_positions.append(13) #13 word index\n",
        "  \n",
        "\n",
        "    # if start position is None, the answer passage has been truncated\n",
        "    if start_positions[-1] is None:\n",
        "      start_positions[-1] = tokenizer.model_max_length\n",
        "    if end_positions[-1] is None:\n",
        "      end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "  encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(valid_encodings, valid_answers)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU-mZO2RMwVl",
        "outputId": "0c849779-3ab6-4d6b-8b25-73b30fc1f1ff"
      },
      "source": [
        "train_encodings['start_positions'][:10]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[114, 40, 65, 85, 20, 51, 85, 111, 27, 166]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC5t8iOyORg-"
      },
      "source": [
        "class SQuAD_Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings):\n",
        "    self.encodings = encodings\n",
        "  def __getitem__(self, idx):\n",
        "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfpQgBOCPLwh"
      },
      "source": [
        "train_dataset = SQuAD_Dataset(train_encodings)\n",
        "valid_dataset = SQuAD_Dataset(valid_encodings)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8APUSaCswlID"
      },
      "source": [
        "### **Dataloaders üîÅ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROBQQLmNwGbb"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkkgktrwPYhy"
      },
      "source": [
        "## Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8lPIP0zl5uD",
        "outputId": "abae60ca-3c79-45aa-9987-958acf46ecf7"
      },
      "source": [
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh_2--xXwW6o",
        "outputId": "f267f727-1bd1-4440-a0b1-0f00a8aad166"
      },
      "source": [
        "# Check on the available device - use GPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Working on {device}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOXHj73UEh7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99c37fb-a867-4218-d97a-9d03a71d0e8f"
      },
      "source": [
        "%%time\n",
        "from transformers import AdamW\n",
        "\n",
        "N_EPOCHS = 2\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  loop = tqdm(train_loader, leave=True)\n",
        "  for batch in loop:\n",
        "    optim.zero_grad()\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "    loss = outputs[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    loop.set_description(f'Epoch {epoch+1}')\n",
        "    loop.set_postfix(loss=loss.item())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [06:43<00:00,  1.61s/it, loss=1.74]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [06:43<00:00,  1.61s/it, loss=1.04]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13min 12s, sys: 3.19 s, total: 13min 16s\n",
            "Wall time: 13min 30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1,2,3,4,5....,10\n",
        "# Weights = 0\n",
        "# 0.1\n",
        "# 0.12\n",
        "# 0.20\n",
        "# ...\n",
        "# 0.45\n",
        "\n",
        "# Epoch 2\n",
        "\n",
        "# 0.47\n",
        "# 0.49"
      ],
      "metadata": {
        "id": "XePLdZj2N9cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_uwZMDWlOjtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-HEtYKlbhad",
        "outputId": "4be4b1af-72b5-461c-9215-16b7a30af167"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0422, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFY9n5hSFjfT"
      },
      "source": [
        "**Save the model in my drive in order not to run it each time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4NXG5UGWWQ9"
      },
      "source": [
        "#model_path = '/content/drive/MyDrive/BERT-SQuAD'\n",
        "#model.save_pretrained(model_path)\n",
        "#tokenizer.save_pretrained(model_path)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuFwUaF8BR3H"
      },
      "source": [
        "**Respectively, load the saved model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aslUE82N73mu"
      },
      "source": [
        "#from transformers import BertForQuestionAnswering, BertTokenizerFast\n",
        "\n",
        "#model_path = '/content/drive/MyDrive/BERT-SQuAD'\n",
        "#model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "#tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "\n",
        "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "#print(f'Working on {device}')\n",
        "\n",
        "#model = model.to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIuUtJhBFo5l"
      },
      "source": [
        "### **Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZd-NV1WxOZg",
        "outputId": "e2e4239d-6c5c-4933-8be2-285b7c26c459"
      },
      "source": [
        "# model.eval()\n",
        "\n",
        "# acc = []\n",
        "# predict_start_index = []\n",
        "# predict_end_index = []\n",
        "\n",
        "# for batch in tqdm(valid_loader):\n",
        "#   with torch.no_grad():\n",
        "#     input_ids = batch['input_ids'].to(device)\n",
        "#     attention_mask = batch['attention_mask'].to(device)\n",
        "#     start_true = batch['start_positions'].to(device)\n",
        "#     end_true = batch['end_positions'].to(device)\n",
        "    \n",
        "#     outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "#     start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
        "#     end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
        "\n",
        "#     predict_start_index.append(start_pred)\n",
        "#     predict_end_index.append(end_pred)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:17<00:00,  1.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(question,context):\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
        "    inputs.to(device)\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "    answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
        "    answer_end = torch.argmax(outputs[1]) + 1 \n",
        "\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "9aWSMvKAddhQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(valid_contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jocq2h1Dddko",
        "outputId": "937cdc90-e53c-4d8e-c1eb-d6f5169c7f0e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(valid_contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40sSvqfbfewN",
        "outputId": "9ddfe9af-4824-44e5-f606-c30274233bdd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_contexts[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "OC0wVfjifcoc",
        "outputId": "c0c937da-ce6f-41de-d370-1da4df6232fd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Manhattan's skyline, with its many skyscrapers, is universally recognized, and the city has been home to several of the tallest buildings in the world. As of 2011, New York City had 5,937 high-rise buildings, of which 550 completed structures were at least 330 feet (100 m) high, both second in the world after Hong Kong, with over 50 completed skyscrapers taller than 656 feet (200 m). These include the Woolworth Building (1913), an early gothic revival skyscraper built with massively scaled gothic detailing.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_questions[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4NwT92PkddnV",
        "outputId": "08c0c81f-899e-4343-eb51-56d4b6403db7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In what year was the Woolworth Building completed?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_answers[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR9CIpk6fUC5",
        "outputId": "50a9ab95-d781-423c-c80c-e11713facf6f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_start': 425, 'text': ['1913'], 'answer_end': 429}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = get_prediction(valid_questions[50], valid_contexts[50])\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-8FbadZsfwWn",
        "outputId": "eb27f3af-1c9b-4a55-ecc7-75624dc25f35"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1913'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_answer = []\n",
        "\n",
        "for i in range(len(valid_answers)):\n",
        "\n",
        "     original_answers = valid_answers[i]['text'][0]\n",
        "     original_answer.append(original_answers)"
      ],
      "metadata": {
        "id": "qBuii3iAl80r"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_answer = []\n",
        "\n",
        "for i in range(len(valid_questions)):\n",
        "\n",
        "     answer = get_prediction(valid_questions[i], valid_contexts[i])\n",
        "     predicted_answer.append(answer)"
      ],
      "metadata": {
        "id": "ZfQQ32IglJBx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Create a dictionary from the lists\n",
        "data = {'Question': valid_questions, 'Context': valid_contexts, 'Original_Answer': original_answer, 'Predicted_Answer': predicted_answer}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "-3Y305eWlcK6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "-Ma_B8KxmTW8",
        "outputId": "67ad4b2c-eaee-4287-c20b-83451df2cfb4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Question  \\\n",
              "212        What borough has a Gini Coefficient of 0.6?   \n",
              "235    NYC's fashion industry employs how many people?   \n",
              "363  What is the nickname given to New York City Po...   \n",
              "325  When was the Manhattan Neighborhood Network cr...   \n",
              "477  In minutes, how long does it take for the aver...   \n",
              "92   The highest temperature ever recorded in NYC w...   \n",
              "170  From what country did the largest number of fo...   \n",
              "422    In what year were the Brooklyn Dodgers founded?   \n",
              "192  Out of all African nations, which provided the...   \n",
              "213  What previous mayor of New York is a billionaire?   \n",
              "\n",
              "                                               Context       Original_Answer  \\\n",
              "212  New York City has a high degree of income disp...             Manhattan   \n",
              "235  As of 2013, the global advertising agencies of...               180,000   \n",
              "363  The New York City Police Department (NYPD) has...     New York's Finest   \n",
              "325  New York is also a major center for non-commer...                  1971   \n",
              "477  Public transport is essential in New York City...                  38.4   \n",
              "92   Winters are cold and damp, and prevailing wind...                  1936   \n",
              "170  Approximately 37% of the city's population is ...    Dominican Republic   \n",
              "422  New York City is home to the headquarters of t...                  1882   \n",
              "192  Ecuador, Colombia, Guyana, Peru, and Brazil we...                 Egypt   \n",
              "213  New York City has a high degree of income disp...  Michael R. Bloomberg   \n",
              "\n",
              "                                      Predicted_Answer  \n",
              "212  new york city has a high degree of income disp...  \n",
              "235                                           180, 000  \n",
              "363                                             finest  \n",
              "325  wnyc, a public radio station owned by the city...  \n",
              "477                                                     \n",
              "92                                       cold and damp  \n",
              "170  37 % of the city ' s population is foreign bor...  \n",
              "422                                               1882  \n",
              "192                                                     \n",
              "213                                             4. 6 %  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44ac0258-f9f5-49a1-ad54-acb09db75485\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Context</th>\n",
              "      <th>Original_Answer</th>\n",
              "      <th>Predicted_Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>What borough has a Gini Coefficient of 0.6?</td>\n",
              "      <td>New York City has a high degree of income disp...</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>new york city has a high degree of income disp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>NYC's fashion industry employs how many people?</td>\n",
              "      <td>As of 2013, the global advertising agencies of...</td>\n",
              "      <td>180,000</td>\n",
              "      <td>180, 000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>What is the nickname given to New York City Po...</td>\n",
              "      <td>The New York City Police Department (NYPD) has...</td>\n",
              "      <td>New York's Finest</td>\n",
              "      <td>finest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>When was the Manhattan Neighborhood Network cr...</td>\n",
              "      <td>New York is also a major center for non-commer...</td>\n",
              "      <td>1971</td>\n",
              "      <td>wnyc, a public radio station owned by the city...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>In minutes, how long does it take for the aver...</td>\n",
              "      <td>Public transport is essential in New York City...</td>\n",
              "      <td>38.4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>The highest temperature ever recorded in NYC w...</td>\n",
              "      <td>Winters are cold and damp, and prevailing wind...</td>\n",
              "      <td>1936</td>\n",
              "      <td>cold and damp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>From what country did the largest number of fo...</td>\n",
              "      <td>Approximately 37% of the city's population is ...</td>\n",
              "      <td>Dominican Republic</td>\n",
              "      <td>37 % of the city ' s population is foreign bor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>In what year were the Brooklyn Dodgers founded?</td>\n",
              "      <td>New York City is home to the headquarters of t...</td>\n",
              "      <td>1882</td>\n",
              "      <td>1882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>Out of all African nations, which provided the...</td>\n",
              "      <td>Ecuador, Colombia, Guyana, Peru, and Brazil we...</td>\n",
              "      <td>Egypt</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>What previous mayor of New York is a billionaire?</td>\n",
              "      <td>New York City has a high degree of income disp...</td>\n",
              "      <td>Michael R. Bloomberg</td>\n",
              "      <td>4. 6 %</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44ac0258-f9f5-49a1-ad54-acb09db75485')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44ac0258-f9f5-49a1-ad54-acb09db75485 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44ac0258-f9f5-49a1-ad54-acb09db75485');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhkudboEmZaj",
        "outputId": "0cf80f23-0c87-4f7d-89ac-e3d0d9184d77"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOqoaos3mb5Q"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}